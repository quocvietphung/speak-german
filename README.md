# ğŸ—£ï¸ German Speech Recognition & Pronunciation Evaluation AI

## Overview
This project provides a **full-stack solution** for German pronunciation practice.  
It combines **Automatic Speech Recognition (ASR)** using Whisper, **pronunciation scoring** (WER/CER), and **AI teacher feedback** powered by Azure OpenAI.

---

## âœ¨ Features
- ğŸ¤ Record and transcribe German speech audio (`.webm` supported)
- ğŸ“ Compare spoken text to a reference sentence
- ğŸ“Š Pronunciation score + **Word Error Rate (WER)** and **Character Error Rate (CER)**
- âŒ Identify mispronounced or missing words, with suggestions
- ğŸ‘©â€ğŸ« AI-powered teacher feedback (IPA, stress, tips)
- ğŸŒ™ Modern UI (Next.js + Chakra UI)

---

## ğŸ“¸ Demo Screenshots

### ğŸ¤ Practice Screen
![Practice Demo](demo/demo_practice.png)

### ğŸ‘©â€ğŸ« Feedback Screen
![Feedback Demo](demo/demo_feedback.png)

---

## ğŸ§© Architecture
- **Backend:** Python, Flask, Whisper (Hugging Face), `jiwer`, `soundfile`, `ffmpeg`
- **Frontend:** Next.js 15.4.6, React, Chakra UI, TypeScript
- **AI Feedback:** Azure OpenAI GPT (teacher feedback)

**Flow:**  
1. Frontend records audio  
2. Next.js API sends audio to Flask backend  
3. Whisper transcribes and computes WER/CER + mistakes  
4. Azure OpenAI generates teacher feedback  
5. Results returned to UI  

![System Architecture](demo/speak-german.png)

---

## ğŸ“ Suggested Project Structure

```
speak-german/
â”œâ”€ app.py
â”œâ”€ requirements.txt
â”œâ”€ service/
â”‚  â”œâ”€ asr_service.py
â”‚  â”œâ”€ scoring.py
â”‚  â””â”€ utils.py
â”œâ”€ models/          # Whisper cache
â”œâ”€ demo/            # screenshots
â”œâ”€ docs/
â”‚  â””â”€ slides_beamer.tex
â”œâ”€ frontend/
â”‚  â”œâ”€ .env.local.example
â”‚  â”œâ”€ package.json
â”‚  â””â”€ src/
â”‚     â”œâ”€ pages/api/   # proxy â†’ Flask
â”‚     â”œâ”€ components/
â”‚     â””â”€ pages/
```

---

## ğŸš€ Getting Started

### 1) Backend (Flask)

```bash
git clone https://github.com/quocvietphung/speak-german.git
cd speak-german
python -m venv .venv
source .venv/bin/activate     # Linux/Mac
# .venv\Scripts\activate    # Windows
pip install -r requirements.txt
python app.py                 # runs on http://localhost:8000
```

> Requirement: `ffmpeg` installed and in PATH.

### 2) Frontend (Next.js)

```bash
cd frontend
npm install        # or: yarn install
```

Create `frontend/.env.local`:

```
AZURE_OPENAI_API_KEY=your-key-here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT_NAME=your-deployment
AZURE_OPENAI_API_VERSION=2024-02-15-preview
BACKEND_BASE_URL=http://localhost:8000
```

Run dev server:

```bash
npm run dev        # or: yarn dev
# open http://localhost:3000
```

---

## ğŸ“Š Evaluation Metrics (TensorBoard)

During fine-tuning, both **loss** and **WER (Word Error Rate)** decreased steadily,  
showing that the Whisper model adapted well to the German Common Voice subset.

![Evaluation Metrics](demo/tensorboard_eval.png)

- **Loss:** dropped continuously â†’ model learning stably  
- **WER:** improved from ~0.35 â†’ ~0.32 on validation set  
- **Runtime & samples/sec:** fluctuated at first, then stabilized  
- **Steps/sec:** consistent after ~400 steps â†’ efficient utilization  

---

## ğŸ“Š Training Metrics (TensorBoard)

The following plots summarize the **training process** of Whisper fine-tuning:

![Training Metrics](demo/tensorboard_train.png)

- **Epoch:** Linear increase (0 â†’ 1), confirming logging per step.  
- **Gradient Norm:** Fluctuations within normal range â†’ no gradient explosion observed.  
- **Learning Rate:** Warmup at the beginning, then decays smoothly as expected.  
- **Training Loss:** Drops quickly at the start, stabilizes around ~0.6.  
- **FLOPs (total_flos):** Shows accumulated compute cost.  
- **Runtime:** Total training time â‰ˆ 17k seconds (~4.7 hours).  
- **Steps per Second:** ~0.05â€“0.1 â†’ relatively slow due to hardware limits.  
- **Samples per Second:** ~0.46 â†’ consistent throughput.  

## ğŸ› ï¸ API Reference

### POST `/api/evaluate`
- **Description:** Transcribes German speech and evaluates pronunciation against `target_text`.

**Request (multipart/form-data):**
- `audio`: `.webm` file
- `target_text`: German reference sentence (string)

**Curl Example:**
```bash
curl -X POST http://localhost:8000/api/evaluate   -F "audio=@sample.webm"   -F 'target_text=Ich trinke morgens gern frisch gebrÃ¼hten Kaffee.'
```

**Response Example:**
```json
{
  "transcript": "ich trinke morgens gern frisch gebrutten kaffee",
  "target_text": "Ich trinke morgens gern frisch gebrÃ¼hten Kaffee.",
  "wer": 0.4512,
  "cer": 0.2029,
  "score": 62.5,
  "mistakes": [
    {"word": "gebrÃ¼hten", "heard": "gebrutten", "type": "substitution"},
    {"word": "Kaffee", "heard": "kaffee", "type": "casing"}
  ],
  "tips": {
    "ipa": "É¡É™ËˆbÊyËtnÌ© ËˆkafeË",
    "stress": "Stress on 'brÃ¼h-' and 'Kaf-'",
    "advice": "Practice long vowels /yË/ and /eË/ in 'brÃ¼hten' and 'Kaffee'."
  },
  "model_used": "fine_tuned"
}
```

### GET `/api/hello`
- **Health check**  
- **Response:**  
```json
{ "message": "Hello from Flask API!" }
```

---

## ğŸ“¦ Requirements

```
flask
flask-cors
transformers==4.55.2
torch==2.8.0
soundfile
jiwer
huggingface_hub
```

Optional: `accelerate`, `numpy`, `protobuf<5`, `ffmpeg-python`.

---

## ğŸ“Š Reference Results (WER/CER)

Subset: **Common Voice DE ~1%**, Whisper-Tiny fine-tuned demo.

| Split       | WER Base | WER FT | CER Base | CER FT |
|------------ |---------:|-------:|---------:|-------:|
| Train       | 0.4152   | **0.3293** | 0.1510   | **0.1152** |
| Validation  | 0.3732   | **0.3192** | 0.1328   | **0.1105** |
| Test        | 0.9721   | **0.4512** | 0.4806   | **0.2029** |

---

## ğŸ§¯ Troubleshooting
- **macOS/M3 (MPS) & fp16:** Avoid `fp16` â†’ use FP32.  
- **`attention_mask` warning:** Provide `attention_mask` if `pad_token == eos_token`.  
- **CORS:** Use `flask-cors` or configure Next.js proxy.  
- **Audio:** Ensure 16kHz mono, `ffmpeg` available.  
- **Model download:** First run may take several minutes.

---

## ğŸ”’ Security & Privacy
- Do not store raw audio/transcripts in production.  
- Clean temporary files, sanitize logs.  
- Protect API with keys & rate limiting.

---

## ğŸ—ºï¸ Roadmap
- Efficient fine-tuning (LoRA/PEFT)  
- Data augmentation (SpecAugment, pitch/speed perturbation)  
- Streaming & low-latency optimization  
- Per-token pronunciation scoring

---

## ğŸ“š References
- Common Voice 13.0: https://huggingface.co/datasets/mozilla-foundation/common_voice_13_0  
- Whisper Tiny: https://huggingface.co/openai/whisper-tiny

---

## ğŸªª License
MIT License Â© 2025 Viet Phung
